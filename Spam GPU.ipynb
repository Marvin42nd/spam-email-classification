{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c049a42",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\npytz: No module named 'pytz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         missing_dependencies\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_dependencies:\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to import required dependencies:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing_dependencies)\n\u001b[0;32m     18\u001b[0m     )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m hard_dependencies, dependency, missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to import required dependencies:\npytz: No module named 'pytz'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import keras\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7422de60",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1096613164.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [4]\u001b[1;36m\u001b[0m\n\u001b[1;33m    import tensorflow-gpu as tf\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow-gpu as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb69b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spam_ham_dataset.csv\", encoding='latin')\n",
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_plot(data):\n",
    "    # finding words along with count\n",
    "     word_counter = collections.Counter([word for sentence in data for word in sentence.split()])\n",
    "     most_count = word_counter.most_common(30) # 30 most common words\n",
    "     # sorted data frame\n",
    "     most_count = pd.DataFrame(most_count, columns=[\"Word\", \"Count\"]).sort_values(by=\"Count\")\n",
    "     most_count.plot.barh(x = \"Word\", y = \"Count\", color=\"green\", figsize=(10, 15))\n",
    "        \n",
    "word_count_plot(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f4bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does preprocessing\n",
    "lem = WordNetLemmatizer()\n",
    "def preprocess(data):\n",
    "    mail = data.lower()\n",
    "    mail = re.sub(\"[^a-z ]\", \"\", mail)\n",
    "    mail = mail.split()\n",
    "    mail = [lem.lemmatize(word) for word in mail if not word in set(stopwords.words('english'))]\n",
    "    mail = \" \".join(mail)\n",
    "    return mail\n",
    "\n",
    "x = data['text'].apply(preprocess)\n",
    "word_count_plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d3a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(data['label'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccec3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x)\n",
    "text2seq = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "maxseq = max([len(i) for i in text2seq])\n",
    "padded = pad_sequences(text2seq, maxlen=maxseq, padding='pre')\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd580cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d52a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "TOT_SIZE = len(tokenizer.word_index) + 1\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(Embedding(TOT_SIZE, 32, input_length=maxseq))\n",
    "lstm.add(LSTM(100, dropout=0.4))\n",
    "'''lstm.add(Dropout(0.4))\n",
    "lstm.add(Dense(20, activation='relu'))\n",
    "lstm.add(Dropout(0.3))'''\n",
    "lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6922545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "lstm.fit(x_train, y_train, epochs=2, validation_split=0.2, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab48bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "y_pred = lstm.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(\"Test Score:{:.2f}%\".format(accuracy_score(y_test, y_pred)*100))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
